# AI Integration Guide

## The Force Multiplier Pattern

EquilateralAgentsâ„¢ transforms your existing AI tools into a coordinated development team. Instead of replacing your AI assistants, we amplify their capabilities through structured orchestration.

## Integration Modes

### ðŸ¤– Mode 1: AI-Assisted Orchestration (Recommended)

Run EquilateralAgents within your favorite AI coding assistant for maximum intelligence:

```bash
# In Claude Code, Cursor, Continue, Windsurf, etc:
npm run wow
```

Your AI assistant will:
- Interpret agent analysis results
- Generate fixes based on agent findings
- Coordinate multi-step workflows
- Make intelligent decisions from structured data

**Example Flow:**
1. TestOrchestrationAgent finds failing tests
2. AI assistant reads structured failure data
3. AI generates targeted fixes
4. DeploymentValidationAgent verifies changes
5. AI assistant commits with proper context

### ðŸ”§ Mode 2: Bring Your Own LLM (BYOL)

Use your existing AI subscriptions (Copilot, Claude, GPT-4) directly with agents:

```javascript
// Configure in .env
LLM_PROVIDER=openai       # or: anthropic, copilot, azure
LLM_API_KEY=your-key-here
LLM_MODEL=gpt-4           # optional, uses provider default

// Agents automatically enhance their analysis
const analyzer = new CodeAnalyzerAgent({
  enableAI: true  // Uses your configured LLM
});
```

**Supported Providers:**
- OpenAI (GPT-3.5/4)
- Anthropic (Claude)
- GitHub Copilot (via API)
- Azure OpenAI
- Local models (Ollama)

### ðŸš€ Mode 3: Standalone Operation

Works without any AI for basic automation:

```javascript
const orchestrator = new AgentOrchestrator();
// Agents provide structured data perfect for CI/CD pipelines
```

## Real-World Examples

### Intelligent Test Fixing
```javascript
// When AI-enhanced, this workflow can actually fix tests
await orchestrator.executeWorkflow('test-fix-cycle', {
  projectPath: './my-project',
  aiEnabled: true,  // Agent outputs become AI prompts
  autoFix: true     // AI attempts fixes automatically
});
```

### Smart Code Review
```javascript
// AI interprets security scanner results and suggests fixes
await orchestrator.executeWorkflow('security-review', {
  projectPath: './src',
  aiProvider: 'anthropic',  // Use Claude for security analysis
  explainFindings: true      // AI explains issues in context
});
```

### Context-Aware Deployment
```javascript
// AI makes deployment decisions based on validation results
await orchestrator.executeWorkflow('smart-deploy', {
  environment: 'staging',
  aiDecisionMaking: true  // AI evaluates if safe to deploy
});
```

## The Orchestration Advantage

Traditional AI coding assistants work in isolation. EquilateralAgents provides:

1. **Structured Context** - Agents provide consistent, parseable data
2. **Sequential Intelligence** - Each agent builds on previous findings
3. **Verification Loops** - Agents validate AI-generated changes
4. **Memory Between Runs** - Workflow history informs future decisions

## Configuration Examples

### .env for BYOL Setup
```bash
# OpenAI Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4

# Or Anthropic Configuration
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-opus

# Or GitHub Copilot
LLM_PROVIDER=copilot
GITHUB_TOKEN=ghp_...

# Or Local Model (Ollama)
LLM_PROVIDER=ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=codellama
```

### Agent AI Configuration
```javascript
// Enable AI for specific capabilities
const agent = new CodeAnalyzerAgent({
  ai: {
    enabled: true,
    capabilities: [
      'explain_complexity',  // AI explains why code is complex
      'suggest_refactors',   // AI suggests improvements
      'generate_tests'       // AI writes test cases
    ],
    temperature: 0.3,  // Lower = more focused
    maxTokens: 2000
  }
});
```

## Prompt Engineering Tips

When agents are AI-enhanced, they generate structured prompts:

```javascript
// Agent output becomes AI context
{
  role: "system",
  content: "You are analyzing test failures for automatic repair"
}
{
  role: "user",
  content: agentAnalysis  // Structured failure data
}
```

## Commercial Edition Advantages

The open core requires you to bring your own LLM. The commercial edition includes:

- âœ¨ Embedded intelligence (no API keys needed)
- âœ¨ Optimized routing to appropriate models
- âœ¨ Cost-effective model selection per task
- âœ¨ Fallback chains for reliability
- âœ¨ Fine-tuned models for specific workflows

---

## Getting Started

1. **Try with your AI assistant first** - Experience the full power
2. **Configure BYOL if needed** - Use your existing subscriptions
3. **Run standalone for CI/CD** - Basic automation without AI

```bash
# Quick test with AI enhancement
export LLM_PROVIDER=openai
export OPENAI_API_KEY=your-key
npm run wow  # See the magic happen
```

## FAQ

**Q: Do I need an LLM to use EquilateralAgents?**
A: No, agents work standalone. But AI integration unlocks their full potential.

**Q: Which AI assistant works best?**
A: Any assistant that can read structured output. Claude Code and Cursor are particularly effective.

**Q: Can I use free tier LLMs?**
A: Yes! Configure Ollama locally or use free tier API limits.

**Q: How is this different from just using ChatGPT?**
A: Agents provide structure, verification, and orchestration that pure LLMs lack. It's the difference between asking for help and having an organized team.

---

*Note: Commercial edition includes embedded intelligence without requiring external LLM subscriptions. Contact info@happyhippo.ai for details.*